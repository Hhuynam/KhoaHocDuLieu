{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0270a326",
   "metadata": {},
   "source": [
    "\n",
    "## **5.1. Machine Learning l√† g√¨?**\n",
    "\n",
    "### **5.1.1. Kh√°i ni·ªám c∆° b·∫£n**\n",
    "\n",
    "Machine Learning (ML) l√† ph∆∞∆°ng ph√°p x√¢y d·ª±ng m√¥ h√¨nh to√°n h·ªçc t·ª´ d·ªØ li·ªáu. M√¥ h√¨nh c√≥ kh·∫£ nƒÉng t·ª± ƒëi·ªÅu ch·ªânh ƒë·ªÉ th√≠ch nghi v·ªõi d·ªØ li·ªáu ƒë√£ quan s√°t, t·ª´ ƒë√≥ d·ª± ƒëo√°n ho·∫∑c ph√¢n t√≠ch d·ªØ li·ªáu m·ªõi. Kh√¥ng gi·ªëng nh∆∞ c√°c ch∆∞∆°ng tr√¨nh truy·ªÅn th·ªëng, ML h·ªçc t·ª´ d·ªØ li·ªáu thay v√¨ ƒë∆∞·ª£c l·∫≠p tr√¨nh r√µ r√†ng t·ª´ng b∆∞·ªõc.\n",
    "\n",
    "> üåç **·ª®ng d·ª•ng th·ª±c t·∫ø**:\n",
    "> - D·ª± ƒëo√°n nhu c·∫ßu th·ªã tr∆∞·ªùng t·ª´ d·ªØ li·ªáu b√°n h√†ng  \n",
    "> - Nh·∫≠n di·ªán khu√¥n m·∫∑t, gi·ªçng n√≥i  \n",
    "> - Ph√¢n lo·∫°i th∆∞ r√°c, g·ª£i √Ω video, s·∫£n ph·∫©m  \n",
    "\n",
    "---\n",
    "\n",
    "### **5.1.2. C√°c lo·∫°i h·ªçc m√°y**\n",
    "\n",
    "- **Supervised Learning**: h·ªçc t·ª´ d·ªØ li·ªáu c√≥ nh√£n (v√≠ d·ª•: d·ª± ƒëo√°n gi√° nh√†, ph√¢n lo·∫°i ·∫£nh).\n",
    "- **Unsupervised Learning**: h·ªçc t·ª´ d·ªØ li·ªáu kh√¥ng nh√£n (v√≠ d·ª•: ph√¢n c·ª•m kh√°ch h√†ng).\n",
    "- **Semi-supervised Learning**: k·∫øt h·ª£p c·∫£ hai khi nh√£n b·ªã thi·∫øu ho·∫∑c kh√¥ng ƒë·∫ßy ƒë·ªß.\n",
    "\n",
    "> ‚úîÔ∏è **L·ª£i √≠ch**: ML m·ªü ra kh·∫£ nƒÉng t·ª± ƒë·ªông h√≥a, m·ªü r·ªông ph√¢n t√≠ch d·ªØ li·ªáu v·ªõi t·ªëc ƒë·ªô v∆∞·ª£t tr·ªôi so v·ªõi kh·∫£ nƒÉng con ng∆∞·ªùi.\n",
    "\n",
    "---\n",
    "\n",
    "## **5.2. Gi·ªõi thi·ªáu Scikit-Learn**\n",
    "\n",
    "### **5.2.1. T·ªïng quan v·ªÅ th∆∞ vi·ªán Scikit-Learn**\n",
    "\n",
    "Scikit-Learn l√† m·ªôt th∆∞ vi·ªán m√£ ngu·ªìn m·ªü n·ªïi b·∫≠t trong Python d√πng ƒë·ªÉ tri·ªÉn khai thu·∫≠t to√°n ML, cung c·∫•p:\n",
    "- C√°c m√¥ h√¨nh h·ªçc m√°y chu·∫©n h√≥a: classification, regression, clustering,...\n",
    "- Giao di·ªán API th·ªëng nh·∫•t, d·ªÖ h·ªçc, d·ªÖ d√πng\n",
    "- T√≠ch h·ª£p v·ªõi NumPy, Pandas, Matplotlib\n",
    "\n",
    "---\n",
    "\n",
    "### **5.2.2. C√°ch s·ª≠ d·ª•ng Scikit-Learn theo 5 b∆∞·ªõc**\n",
    "\n",
    "1. **Ch·ªçn l·ªõp m√¥ h√¨nh**: `LinearRegression`, `KNeighborsClassifier`, v.v.  \n",
    "2. **C√†i ƒë·∫∑t si√™u tham s·ªë**: nh∆∞ `n_neighbors=3`  \n",
    "3. **Chu·∫©n b·ªã d·ªØ li·ªáu**: t√°ch `X` v√† `y`  \n",
    "4. **Hu·∫•n luy·ªán**: `.fit(X_train, y_train)`  \n",
    "5. **D·ª± ƒëo√°n**: `.predict(X_test)` ho·∫∑c `.transform()`\n",
    "\n",
    "> üìå **·ª®ng d·ª•ng th·ª±c t·∫ø**: nhanh ch√≥ng th·ª≠ nghi·ªám nhi·ªÅu m√¥ h√¨nh ƒë·ªÉ ch·ªçn m√¥ h√¨nh t·ªëi ∆∞u m√† kh√¥ng vi·∫øt l·∫°i nhi·ªÅu code.\n",
    "\n",
    "---\n",
    "\n",
    "## **5.3. Si√™u tham s·ªë v√† ƒë√°nh gi√° m√¥ h√¨nh**\n",
    "\n",
    "### **5.3.1. Si√™u tham s·ªë l√† g√¨?**\n",
    "\n",
    "- L√† c√°c tham s·ªë ƒë∆∞·ª£c thi·∫øt l·∫≠p tr∆∞·ªõc khi hu·∫•n luy·ªán, kh√¥ng h·ªçc ƒë∆∞·ª£c t·ª´ d·ªØ li·ªáu.\n",
    "- V√≠ d·ª•: s·ªë l√° trong c√¢y quy·∫øt ƒë·ªãnh, s·ªë c·ª•m trong KMeans,...\n",
    "\n",
    "### **5.3.2. X√°c th·ª±c m√¥ h√¨nh ‚Äì T·∫°i sao c·∫ßn?**\n",
    "\n",
    "N·∫øu ƒë√°nh gi√° m√¥ h√¨nh tr√™n ch√≠nh d·ªØ li·ªáu hu·∫•n luy·ªán, ta d·ªÖ b·ªã ‚Äú·∫£o t∆∞·ªüng‚Äù v·ªÅ ƒë·ªô ch√≠nh x√°c (overfitting). Gi·∫£i ph√°p:\n",
    "- **Train/Test split**\n",
    "- **Cross-validation**: chia t·∫≠p d·ªØ li·ªáu nhi·ªÅu l·∫ßn v√† ho√°n ƒë·ªïi vai tr√≤ train/test\n",
    "- **GridSearchCV**: th·ª≠ nhi·ªÅu b·ªô si√™u tham s·ªë ƒë·ªÉ t√¨m c√°i t·ªët nh·∫•t\n",
    "\n",
    "---\n",
    "\n",
    "### **5.3.3. ƒê√°nh ƒë·ªïi bias‚Äìvariance**\n",
    "\n",
    "- **Bias cao** ‚Üí m√¥ h√¨nh ƒë∆°n gi·∫£n, underfitting  \n",
    "- **Variance cao** ‚Üí m√¥ h√¨nh qu√° ph·ª©c t·∫°p, overfitting  \n",
    "\n",
    "> ‚öôÔ∏è **Th·ª±c h√†nh t·ªët**: D√πng bi·ªÉu ƒë·ªì learning curve ƒë·ªÉ theo d√µi ch·∫•t l∆∞·ª£ng hu·∫•n luy·ªán v√† d·ª± ƒëo√°n theo k√≠ch th∆∞·ªõc d·ªØ li·ªáu.\n",
    "\n",
    "> üåü **·ª®ng d·ª•ng**: T·ªëi ∆∞u m√¥ h√¨nh trong d·ª± ƒëo√°n t√†i ch√≠nh, y t·∫ø, d·ª± b√°o kinh doanh ‚Äì n∆°i hi·ªáu qu·∫£ d·ª± ƒëo√°n quy·∫øt ƒë·ªãnh l·ª£i nhu·∫≠n ho·∫∑c sinh m·∫°ng.\n",
    "\n",
    "---\n",
    "\n",
    "## **5.4. K·ªπ thu·∫≠t x√¢y d·ª±ng ƒë·∫∑c tr∆∞ng (Feature Engineering)**\n",
    "\n",
    "### **5.4.1. T·∫°i sao c·∫ßn k·ªπ thu·∫≠t ƒë·∫∑c tr∆∞ng?**\n",
    "\n",
    "D·ªØ li·ªáu th·ª±c t·∫ø hi·∫øm khi s·∫µn s√†ng ƒë∆∞a v√†o m√¥ h√¨nh ML. Ph·∫£i chuy·ªÉn ƒë·ªïi v·ªÅ d·∫°ng s·ªë h·ªçc ƒë∆∞·ª£c `[n_samples, n_features]` ‚Üí qu√° tr√¨nh ƒë√≥ g·ªçi l√† feature engineering.\n",
    "\n",
    "---\n",
    "\n",
    "### **5.4.2. M·ªôt s·ªë k·ªπ thu·∫≠t ph·ªï bi·∫øn**\n",
    "\n",
    "- **Bi·∫øn ph√¢n lo·∫°i** ‚Üí One-hot encoding  \n",
    "- **D·ªØ li·ªáu vƒÉn b·∫£n** ‚Üí CountVectorizer, TF-IDF  \n",
    "- **D·ªØ li·ªáu ·∫£nh** ‚Üí Vector ƒë·∫∑c tr∆∞ng  \n",
    "- **D·ªØ li·ªáu thi·∫øu** ‚Üí Impute b·∫±ng trung b√¨nh, trung v·ªã  \n",
    "- **D·∫´n xu·∫•t ƒë·∫∑c tr∆∞ng** ‚Üí th√™m `x¬≤`, `log(x)`, v.v.  \n",
    "- **T·ª± ƒë·ªông h√≥a** ‚Üí d√πng `Pipeline` ƒë·ªÉ g·ªôp b∆∞·ªõc x·ª≠ l√Ω\n",
    "\n",
    "```python\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy=\"mean\"),\n",
    "    PolynomialFeatures(degree=3),\n",
    "    LinearRegression()\n",
    ")\n",
    "```\n",
    "\n",
    "> üß† **·ª®ng d·ª•ng**:  \n",
    "> - Bi·∫øn vƒÉn b·∫£n feedback kh√°ch h√†ng th√†nh d·ªØ li·ªáu ƒë·ªãnh l∆∞·ª£ng  \n",
    "> - T·ª± ƒë·ªông h√≥a x·ª≠ l√Ω d·ªØ li·ªáu trong h·ªá th·ªëng AI  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425d0121",
   "metadata": {},
   "source": [
    "\n",
    "## **5.5. Ph√¢n lo·∫°i v·ªõi Naive Bayes**\n",
    "\n",
    "### **5.5.1. √ù t∆∞·ªüng v√† c√¥ng th·ª©c Bayes**\n",
    "\n",
    "Naive Bayes l√† nh√≥m thu·∫≠t to√°n ph√¢n lo·∫°i c·ª±c k·ª≥ ƒë∆°n gi·∫£n, nhanh v√† hi·ªáu qu·∫£ trong nhi·ªÅu t√¨nh hu·ªëng. Thu·∫≠t to√°n n√†y d·ª±a tr√™n ƒë·ªãnh l√Ω Bayes ƒë·ªÉ t√≠nh to√°n x√°c su·∫•t m·ªôt nh√£n (label) xu·∫•t hi·ªán d·ª±a tr√™n c√°c ƒë·∫∑c tr∆∞ng quan s√°t ƒë∆∞·ª£c:\n",
    "\n",
    "\\[\n",
    "P(L|X) = \\frac{P(X|L) \\cdot P(L)}{P(X)}\n",
    "\\]\n",
    "\n",
    "Trong ƒë√≥:\n",
    "- \\( P(L|X) \\): x√°c su·∫•t c√≥ nh√£n L khi bi·∫øt X\n",
    "- \\( P(X|L) \\): x√°c su·∫•t t·∫°o ra X t·ª´ l·ªõp L (m√¥ h√¨nh sinh)\n",
    "- \\( P(L) \\): x√°c su·∫•t ti√™n nghi·ªám c·ªßa l·ªõp\n",
    "- \\( P(X) \\): x√°c su·∫•t quan s√°t X (h·∫±ng s·ªë trong m·ªçi l·ªõp)\n",
    "\n",
    "> ƒêi·ªÉm \"naive\" n·∫±m ·ªü gi·∫£ ƒë·ªãnh **c√°c ƒë·∫∑c tr∆∞ng l√† ƒë·ªôc l·∫≠p** v·ªõi nhau trong m·ªói l·ªõp ‚Äì ƒëi·ªÅu n√†y kh√¥ng ƒë√∫ng trong th·ª±c t·∫ø nh∆∞ng gi√∫p m√¥ h√¨nh r·∫•t nhanh v√† v·∫´n kh√° hi·ªáu qu·∫£.\n",
    "\n",
    "---\n",
    "\n",
    "### **5.5.2. C√°c bi·∫øn th·ªÉ Naive Bayes trong Scikit-Learn**\n",
    "\n",
    "| Bi·∫øn th·ªÉ | M√¥ t·∫£ | D√πng khi... |\n",
    "|----------|-------|-------------|\n",
    "| `GaussianNB` | ƒê·∫∑c tr∆∞ng li√™n t·ª•c, ph√¢n ph·ªëi chu·∫©n | D·ªØ li·ªáu d·∫°ng s·ªë (ƒëi·ªÉm s·ªë, gi√° tr·ªã c·∫£m bi·∫øn) |\n",
    "| `MultinomialNB` | ƒê·∫∑c tr∆∞ng r·ªùi r·∫°c, l√† ƒë·∫øm s·ªë l∆∞·ª£ng | Ph√¢n lo·∫°i vƒÉn b·∫£n, t·∫ßn su·∫•t t·ª´ |\n",
    "| `BernoulliNB` | ƒê·∫∑c tr∆∞ng nh·ªã ph√¢n (0/1) | D·ªØ li·ªáu ki·ªÉu c√≥/kh√¥ng: c√≥ email, c√≥ ƒë∆∞·ªùng d·∫´n |\n",
    "\n",
    "---\n",
    "\n",
    "### **5.5.3. V√≠ d·ª•: Gaussian Naive Bayes v·ªõi d·ªØ li·ªáu 2 chi·ªÅu**\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# T·∫°o d·ªØ li·ªáu 2 c·ª•m\n",
    "X, y = make_blobs(n_samples=100, centers=2, random_state=2, cluster_std=1.5)\n",
    "\n",
    "# Hu·∫•n luy·ªán m√¥ h√¨nh\n",
    "model = GaussianNB()\n",
    "model.fit(X, y)\n",
    "\n",
    "# D·ª± ƒëo√°n d·ªØ li·ªáu m·ªõi\n",
    "rng = np.random.RandomState(0)\n",
    "Xnew = [-6, -14] + [14, 18] * rng.rand(2000, 2)\n",
    "ynew = model.predict(Xnew)\n",
    "\n",
    "# V·∫Ω k·∫øt qu·∫£\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='RdBu')\n",
    "plt.scatter(Xnew[:, 0], Xnew[:, 1], c=ynew, s=20, cmap='RdBu', alpha=0.1)\n",
    "plt.title(\"Bi√™n quy·∫øt ƒë·ªãnh c·ªßa GaussianNB\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **5.5.4. V√≠ d·ª•: Ph√¢n lo·∫°i vƒÉn b·∫£n v·ªõi MultinomialNB**\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# L·∫•y d·ªØ li·ªáu\n",
    "categories = ['sci.space', 'soc.religion.christian', 'comp.graphics']\n",
    "train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "\n",
    "# Pipeline\n",
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "model.fit(train.data, train.target)\n",
    "\n",
    "# D·ª± ƒëo√°n\n",
    "labels = model.predict(test.data)\n",
    "```\n",
    "\n",
    "> ·ª®ng d·ª•ng th·ª±c t·∫ø:\n",
    "> - Ph√¢n lo·∫°i email: spam / kh√¥ng spam\n",
    "> - G·ª£i √Ω b√†i b√°o / phim / tin t·ª©c theo ch·ªß ƒë·ªÅ\n",
    "> - Nh·∫≠n d·∫°ng ng·ªØ nghƒ©a c·ªßa ƒëo·∫°n vƒÉn b·∫£n\n",
    "\n",
    "---\n",
    "\n",
    "### **5.5.5. ∆Øu ƒëi·ªÉm & nh∆∞·ª£c ƒëi·ªÉm**\n",
    "\n",
    "| ∆Øu ƒëi·ªÉm | Nh∆∞·ª£c ƒëi·ªÉm |\n",
    "|--------|------------|\n",
    "| Hu·∫•n luy·ªán c·ª±c nhanh | Gi·∫£ ƒë·ªãnh ƒë·ªôc l·∫≠p kh√¥ng th·ª±c t·∫ø |\n",
    "| C√≥ x√°c su·∫•t d·ª± ƒëo√°n (predict_proba) | Kh√¥ng t·ªët khi d·ªØ li·ªáu c√≥ m·ªëi quan h·ªá ph·ª©c t·∫°p |\n",
    "| √çt tham s·ªë c·∫ßn ƒëi·ªÅu ch·ªânh | Kh√¥ng h·ªçc ƒë∆∞·ª£c t∆∞∆°ng quan gi·ªØa ƒë·∫∑c tr∆∞ng |\n",
    "\n",
    "---\n",
    "\n",
    "### **5.5.6. C√°c l·ªói th∆∞·ªùng g·∫∑p**\n",
    "\n",
    "| L·ªói | Nguy√™n nh√¢n | C√°ch x·ª≠ l√Ω |\n",
    "|-----|-------------|------------|\n",
    "| `ValueError: Input contains NaN` | D·ªØ li·ªáu thi·∫øu | D√πng `SimpleImputer` ƒë·ªÉ thay th·∫ø |\n",
    "| D·ª± ƒëo√°n sai to√†n b·ªô | Kh√¥ng kh·ªõp ƒë·ªãnh d·∫°ng ƒë·∫∑c tr∆∞ng | Ki·ªÉm tra `vectorizer`, x·ª≠ l√Ω tr∆∞·ªõc d·ªØ li·ªáu |\n",
    "\n",
    "---\n",
    "\n",
    "## **5.5.7. B√†i t·∫≠p th·ª±c h√†nh c√≥ l·ªùi gi·∫£i**\n",
    "\n",
    "---\n",
    "\n",
    "### **B√†i 1: Ph√¢n lo·∫°i lo√†i hoa Iris v·ªõi GaussianNB**\n",
    "\n",
    "**Y√™u c·∫ßu**: D·ª± ƒëo√°n lo√†i hoa d·ª±a tr√™n 4 ƒë·∫∑c tr∆∞ng.  \n",
    "**D·ªØ li·ªáu**: `sklearn.datasets.load_iris()`\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(iris.data, iris.target, random_state=0)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(Xtrain, ytrain)\n",
    "y_pred = model.predict(Xtest)\n",
    "\n",
    "print(\"ƒê·ªô ch√≠nh x√°c:\", accuracy_score(ytest, y_pred))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **B√†i 2: Ph√¢n lo·∫°i email l√† spam b·∫±ng MultinomialNB**\n",
    "\n",
    "**Y√™u c·∫ßu**: D·ª± ƒëo√°n xem email l√† spam hay kh√¥ng  \n",
    "**D·ªØ li·ªáu**: file CSV g·ªìm n·ªôi dung email + nh√£n\n",
    "\n",
    "**C√°ch l√†m**:\n",
    "- ƒê·ªçc file b·∫±ng Pandas\n",
    "- T√°ch t·∫≠p hu·∫•n luy·ªán v√† ki·ªÉm tra\n",
    "- D√πng `TfidfVectorizer()` + `MultinomialNB()`\n",
    "\n",
    "---\n",
    "\n",
    "### **B√†i 3: X√¢y d·ª±ng h√†m d·ª± ƒëo√°n vƒÉn b·∫£n theo ch·ªß ƒë·ªÅ**\n",
    "\n",
    "```python\n",
    "def predict_category(s, train=train, model=model):\n",
    "    pred = model.predict([s])\n",
    "    return train.target_names[pred[0]]\n",
    "\n",
    "print(predict_category(\"NASA launched a new satellite\"))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **B√†i 4: So s√°nh GaussianNB v√† MultinomialNB tr√™n t·∫≠p Digits**\n",
    "\n",
    "**Y√™u c·∫ßu**: Ph√¢n lo·∫°i ch·ªØ s·ªë vi·∫øt tay b·∫±ng 2 m√¥ h√¨nh\n",
    "\n",
    "**G·ª£i √Ω**:\n",
    "- D√πng `load_digits()` t·ª´ `sklearn.datasets`\n",
    "- Chu·∫©n h√≥a d·ªØ li·ªáu: `StandardScaler()` ho·∫∑c `MinMaxScaler()`\n",
    "- ƒê√°nh gi√° b·∫±ng `accuracy_score`\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c0bc7c",
   "metadata": {},
   "source": [
    "\n",
    "## üß† **5.6. Ph√¢n h·ªìi tuy·∫øn t√≠nh (Linear Regression)**\n",
    "\n",
    "### **5.6.1. Gi·ªõi thi·ªáu v√† nhu c·∫ßu**\n",
    "\n",
    "Ph√¢n h·ªìi tuy·∫øn t√≠nh l√† m·ªôt k·ªπ thu·∫≠t c∆° b·∫£n v√† m·∫°nh m·∫Ω trong h·ªçc m√°y d√πng ƒë·ªÉ m√¥ h√¨nh h√≥a m·ªëi quan h·ªá gi·ªØa m·ªôt bi·∫øn ƒë·∫ßu ra li√™n t·ª•c v√† m·ªôt ho·∫∑c nhi·ªÅu bi·∫øn ƒë·∫ßu v√†o. M√¥ h√¨nh c√≥ d·∫°ng:\n",
    "\n",
    "\\[\n",
    "y = a_0 + a_1x_1 + a_2x_2 + \\dots + a_nx_n\n",
    "\\]\n",
    "\n",
    "> üöÄ **Nhu c·∫ßu v√† ·ª©ng d·ª•ng th·ª±c t·∫ø**:\n",
    "> - D·ª± ƒëo√°n gi√° nh√†, gi√° c·ªï phi·∫øu, nhu c·∫ßu ti√™u d√πng\n",
    "> - D·ª± b√°o ch·ªâ s·ªë kinh t·∫ø, chi ph√≠ v·∫≠n h√†nh\n",
    "> - Ph√¢n t√≠ch t√°c ƒë·ªông c·ªßa c√°c y·∫øu t·ªë ƒë·∫øn doanh s·ªë/b·ªánh t·∫≠t\n",
    "\n",
    "### **5.6.2. Khi n√†o n√™n d√πng Linear Regression**\n",
    "\n",
    "‚úÖ **N√™n d√πng khi**:\n",
    "- Bi·∫øn m·ª•c ti√™u l√† **li√™n t·ª•c**  \n",
    "- C√≥ l√Ω do ƒë·ªÉ tin r·∫±ng **quan h·ªá gi·ªØa c√°c bi·∫øn l√† tuy·∫øn t√≠nh**  \n",
    "- C·∫ßn m√¥ h√¨nh ƒë∆°n gi·∫£n, d·ªÖ gi·∫£i th√≠ch v√† tri·ªÉn khai\n",
    "\n",
    "üö´ **Kh√¥ng n√™n d√πng khi**:\n",
    "- D·ªØ li·ªáu c√≥ m·ªëi quan h·ªá phi tuy·∫øn ph·ª©c t·∫°p  \n",
    "- C√≥ nhi·ªÅu ngo·∫°i l·ªá (outliers)  \n",
    "- S·ªë ƒë·∫∑c tr∆∞ng l·ªõn h∆°n s·ªë m·∫´u (d·ªÖ g√¢y overfitting)\n",
    "\n",
    "---\n",
    "\n",
    "### **5.6.3. ∆Øu ƒëi·ªÉm v√† nh∆∞·ª£c ƒëi·ªÉm**\n",
    "\n",
    "| ‚úÖ ∆Øu ƒëi·ªÉm                          | ‚ö†Ô∏è Nh∆∞·ª£c ƒëi·ªÉm                             |\n",
    "|-----------------------------------|------------------------------------------|\n",
    "| ƒê∆°n gi·∫£n, d·ªÖ gi·∫£i th√≠ch           | Kh√¥ng ph√π h·ª£p v·ªõi quan h·ªá phi tuy·∫øn      |\n",
    "| Hi·ªáu su·∫•t hu·∫•n luy·ªán nhanh        | Nh·∫°y c·∫£m v·ªõi ngo·∫°i l·ªá                    |\n",
    "| Cung c·∫•p h·ªá s·ªë ‚Üí hi·ªÉu ƒë∆∞·ª£c ·∫£nh h∆∞·ªüng | Kh√¥ng ho·∫°t ƒë·ªông t·ªët v·ªõi d·ªØ li·ªáu r·ªëi r·∫Øm, t∆∞∆°ng quan cao |\n",
    "\n",
    "---\n",
    "\n",
    "### **5.6.4. C√†i ƒë·∫∑t ƒë∆°n gi·∫£n v·ªõi Scikit-Learn**\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# T·∫°o d·ªØ li·ªáu m√¥ ph·ªèng\n",
    "x = np.random.rand(50) * 10\n",
    "y = 3 * x + 7 + np.random.randn(50)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x.reshape(-1, 1), y)\n",
    "\n",
    "print(\"H·ªá s·ªë g√≥c:\", model.coef_[0])\n",
    "print(\"H·ªá s·ªë ch·∫∑n:\", model.intercept_)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **5.6.5. M·ªü r·ªông m√¥ h√¨nh**\n",
    "\n",
    "- **H·ªìi quy nhi·ªÅu bi·∫øn (Multivariate):** d·ª± ƒëo√°n d·ª±a tr√™n nhi·ªÅu ƒë·∫∑c tr∆∞ng  \n",
    "- **H·ªìi quy phi tuy·∫øn:** k·∫øt h·ª£p v·ªõi `PolynomialFeatures`, ho·∫∑c c√°c h√†m c∆° s·ªü  \n",
    "- **Ch√≠nh quy h√≥a (Regularization):** tr√°nh overfitting  \n",
    "  - Ridge Regression (L2)\n",
    "  - Lasso Regression (L1)\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ **5.6.6. B√†i t·∫≠p th·ª±c h√†nh v·ªõi d·ªØ li·ªáu m·ªü**\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ **B√†i 1: D·ª± ƒëo√°n gi√° nh√† t·∫°i California**\n",
    "\n",
    "**Ngu·ªìn d·ªØ li·ªáu**: [Kaggle - California Housing Prices](https://www.kaggle.com/datasets/camnugent/california-housing-prices)\n",
    "\n",
    "#### **Y√™u c·∫ßu**:\n",
    "D·ª± ƒëo√°n gi√° trung v·ªã c·ªßa nh√† t·∫°i California t·ª´ c√°c ƒë·∫∑c tr∆∞ng nh∆∞: di·ªán t√≠ch, m·∫≠t ƒë·ªô d√¢n c∆∞, s·ªë ph√≤ng,‚Ä¶\n",
    "\n",
    "#### **C√°c b∆∞·ªõc gi·∫£i**:\n",
    "\n",
    "1. T·∫£i v√† ƒë·ªçc d·ªØ li·ªáu  \n",
    "2. Ti·ªÅn x·ª≠ l√Ω: b·ªè gi√° tr·ªã thi·∫øu  \n",
    "3. Chia d·ªØ li·ªáu train/test  \n",
    "4. Hu·∫•n luy·ªán v·ªõi `LinearRegression()`  \n",
    "5. ƒê√°nh gi√° m√¥ h√¨nh b·∫±ng R¬≤, RMSE  \n",
    "6. Ph√¢n t√≠ch √Ω nghƒ©a h·ªá s·ªë\n",
    "\n",
    "#### **L·ªùi gi·∫£i minh h·ªça**:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# B∆∞·ªõc 1-2: T·∫£i v√† x·ª≠ l√Ω\n",
    "data = pd.read_csv(\"housing.csv\")\n",
    "data = data.dropna()\n",
    "X = data.drop(\"median_house_value\", axis=1)\n",
    "y = data[\"median_house_value\"]\n",
    "\n",
    "# B∆∞·ªõc 3: T√°ch t·∫≠p d·ªØ li·ªáu\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# B∆∞·ªõc 4: Hu·∫•n luy·ªán m√¥ h√¨nh\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# B∆∞·ªõc 5: ƒê√°nh gi√°\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"R¬≤:\", r2_score(y_test, y_pred))\n",
    "print(\"RMSE:\", mean_squared_error(y_test, y_pred, squared=False))\n",
    "\n",
    "# B∆∞·ªõc 6: Ph√¢n t√≠ch h·ªá s·ªë\n",
    "print(pd.Series(model.coef_, index=X.columns))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ **B√†i 2: D·ª± ƒëo√°n ch·∫•t l∆∞·ª£ng r∆∞·ª£u vang ƒë·ªè**\n",
    "\n",
    "**Ngu·ªìn d·ªØ li·ªáu**: [Kaggle - Red Wine Quality Dataset](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009)\n",
    "\n",
    "#### **Y√™u c·∫ßu**:\n",
    "D·ª± ƒëo√°n ƒëi·ªÉm ch·∫•t l∆∞·ª£ng c·ªßa r∆∞·ª£u vang ƒë·ªè t·ª´ c√°c ch·ªâ s·ªë h√≥a h·ªçc (pH, ƒë·ªô chua, c·ªìn,...)\n",
    "\n",
    "#### **C√°c b∆∞·ªõc gi·∫£i**:\n",
    "\n",
    "1. T·∫£i d·ªØ li·ªáu `.csv` v√† ƒë·ªçc b·∫±ng Pandas  \n",
    "2. Chia t·∫≠p train/test  \n",
    "3. Hu·∫•n luy·ªán v·ªõi `LinearRegression()`  \n",
    "4. ƒê√°nh gi√° b·∫±ng R¬≤ v√† RMSE  \n",
    "5. Di·ªÖn gi·∫£i t√°c ƒë·ªông c·ªßa t·ª´ng th√¥ng s·ªë h√≥a h·ªçc\n",
    "\n",
    "#### **L·ªùi gi·∫£i minh h·ªça**:\n",
    "\n",
    "```python\n",
    "data = pd.read_csv(\"winequality-red.csv\", sep=';')\n",
    "X = data.drop(\"quality\", axis=1)\n",
    "y = data[\"quality\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"R¬≤:\", r2_score(y_test, y_pred))\n",
    "print(\"RMSE:\", mean_squared_error(y_test, y_pred, squared=False))\n",
    "print(\"H·ªá s·ªë:\", pd.Series(model.coef_, index=X.columns))\n",
    "```\n",
    "\n",
    "> üß† **Ph√¢n t√≠ch**: Nh·ªØng ƒë·∫∑c tr∆∞ng c√≥ h·ªá s·ªë d∆∞∆°ng l·ªõn ‚Üí ƒë√≥ng g√≥p t√≠ch c·ª±c cho ch·∫•t l∆∞·ª£ng r∆∞·ª£u.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå T·ªïng k·∫øt\n",
    "\n",
    "- H·ªìi quy tuy·∫øn t√≠nh l√† m√¥ h√¨nh n·ªÅn t·∫£ng, d·ªÖ ti·∫øp c·∫≠n v√† c√≥ kh·∫£ nƒÉng di·ªÖn gi·∫£i r√µ r√†ng.\n",
    "- D√π ƒë∆°n gi·∫£n, nh∆∞ng v·∫´n hi·ªáu qu·∫£ n·∫øu d·ªØ li·ªáu ph√π h·ª£p (tuy·∫øn t√≠nh, kh√¥ng nhi·ªÅu ngo·∫°i l·ªá).\n",
    "- Hai b√†i t·∫≠p v·ªõi d·ªØ li·ªáu th·ª±c t·∫ø gi√∫p sinh vi√™n v·∫≠n d·ª•ng to√†n b·ªô ki·∫øn th·ª©c ƒë·ªÉ m√¥ h√¨nh h√≥a, gi·∫£i th√≠ch v√† ƒë√°nh gi√° hi·ªáu qu·∫£.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb8b180",
   "metadata": {},
   "source": [
    "\n",
    "# **5.7. Support Vector Machines (SVM)**\n",
    "\n",
    "---\n",
    "\n",
    "## **5.7.1. Gi·ªõi thi·ªáu v√† ·ª©ng d·ª•ng**\n",
    "\n",
    "SVM (Support Vector Machines) l√† m·ªôt thu·∫≠t to√°n h·ªçc c√≥ gi√°m s√°t r·∫•t m·∫°nh cho **ph√¢n lo·∫°i nh·ªã ph√¢n** v√† **h·ªìi quy**. M·ª•c ti√™u c·ªßa SVM l√† t√¨m m·ªôt **si√™u ph·∫≥ng (hyperplane)** ƒë·ªÉ ph√¢n t√°ch hai l·ªõp d·ªØ li·ªáu sao cho **kho·∫£ng c√°ch (margin)** ƒë·∫øn c√°c ƒëi·ªÉm g·∫ßn nh·∫•t c·ªßa m·ªói l·ªõp l√† **l·ªõn nh·∫•t**.\n",
    "\n",
    "> üéØ **·ª®ng d·ª•ng th·ª±c t·∫ø:**\n",
    "> - Nh·∫≠n di·ªán khu√¥n m·∫∑t  \n",
    "> - Ph√¢n lo·∫°i th∆∞ r√°c  \n",
    "> - Ph√¢n t√≠ch t√≠n d·ª•ng, y t·∫ø, gen h·ªçc  \n",
    "> - D·ª± ƒëo√°n l·ªói k·ªπ thu·∫≠t ho·∫∑c h√†nh vi b·∫•t th∆∞·ªùng  \n",
    "\n",
    "---\n",
    "\n",
    "## **5.7.2. L√Ω thuy·∫øt & c√¥ng th·ª©c to√°n h·ªçc**\n",
    "\n",
    "### ‚ùñ **M·ª•c ti√™u c·ªßa SVM tuy·∫øn t√≠nh**\n",
    "\n",
    "V·ªõi t·∫≠p d·ªØ li·ªáu nh·ªã ph√¢n \\( y_i \\in \\{-1, +1\\} \\), b√†i to√°n SVM t√¨m \\( \\mathbf{w}, b \\) sao cho:\n",
    "\n",
    "\\[\n",
    "\\min_{\\mathbf{w}, b} \\ \\frac{1}{2} \\|\\mathbf{w}\\|^2\n",
    "\\quad \\text{v·ªõi ƒëi·ªÅu ki·ªán:} \\quad y_i (\\mathbf{w} \\cdot \\mathbf{x}_i + b) \\geq 1\n",
    "\\]\n",
    "\n",
    "- \\( \\mathbf{x}_i \\): ƒëi·ªÉm d·ªØ li·ªáu ƒë·∫ßu v√†o  \n",
    "- \\( y_i \\): nh√£n c·ªßa m·∫´u th·ª© \\( i \\)  \n",
    "- \\( \\mathbf{w} \\): vector ph√°p tuy·∫øn c·ªßa si√™u ph·∫≥ng  \n",
    "- \\( b \\): ƒë·ªô l·ªách (bias)  \n",
    "- \\( \\|\\mathbf{w}\\| \\): ƒë·ªô d√†i vector ‚Üí li√™n quan ƒë·∫øn ƒë·ªô r·ªông c·ªßa margin\n",
    "\n",
    "### ‚ùñ **Soft Margin ‚Äì cho ph√©p l·ªói**\n",
    "\n",
    "Trong th·ª±c t·∫ø, d·ªØ li·ªáu c√≥ th·ªÉ kh√¥ng ph√¢n t√°ch ho√†n to√†n ‚Üí d√πng bi·∫øn slack \\( \\xi_i \\) v√† tham s·ªë \\( C \\):\n",
    "\n",
    "\\[\n",
    "\\min_{\\mathbf{w}, b, \\xi} \\ \\frac{1}{2} \\|\\mathbf{w}\\|^2 + C \\sum_{i=1}^n \\xi_i\n",
    "\\quad \\text{v·ªõi} \\quad y_i (\\mathbf{w} \\cdot \\mathbf{x}_i + b) \\geq 1 - \\xi_i\n",
    "\\]\n",
    "\n",
    "- \\( C \\): ƒëi·ªÅu khi·ªÉn m·ª©c ƒë·ªô **ch·∫•p nh·∫≠n l·ªói**\n",
    "  - \\( C \\) l·ªõn ‚Üí √≠t cho ph√©p l·ªói (overfitting)\n",
    "  - \\( C \\) nh·ªè ‚Üí cho ph√©p l·ªói nhi·ªÅu h∆°n (t·ªïng qu√°t t·ªët h∆°n)\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùñ **Kernel Trick ‚Äì ph√¢n l·ªõp phi tuy·∫øn**\n",
    "\n",
    "Khi d·ªØ li·ªáu kh√¥ng tuy·∫øn t√≠nh, ta √°nh x·∫° v√†o kh√¥ng gian cao chi·ªÅu th√¥ng qua h√†m kernel:\n",
    "\n",
    "\\[\n",
    "K(\\mathbf{x}, \\mathbf{x'}) = \\phi(\\mathbf{x}) \\cdot \\phi(\\mathbf{x'})\n",
    "\\]\n",
    "\n",
    "| Kernel        | C√¥ng th·ª©c                                           | Khi n√™n d√πng                      |\n",
    "|---------------|-----------------------------------------------------|-----------------------------------|\n",
    "| `linear`      | \\( \\mathbf{x} \\cdot \\mathbf{x'} \\)                  | D·ªØ li·ªáu ph√¢n t√°ch tuy·∫øn t√≠nh      |\n",
    "| `poly`        | \\( (\\mathbf{x} \\cdot \\mathbf{x'} + 1)^d \\)          | Quan h·ªá d·∫°ng ƒëa th·ª©c              |\n",
    "| `rbf`         | \\( \\exp(-\\gamma \\|\\mathbf{x} - \\mathbf{x'}\\|^2) \\)  | Phi tuy·∫øn, ph·ªï bi·∫øn nh·∫•t          |\n",
    "| `sigmoid`     | \\( \\tanh(\\alpha \\mathbf{x} \\cdot \\mathbf{x'} + c) \\)| √çt d√πng, t∆∞∆°ng t·ª± m·∫°ng th·∫ßn kinh  |\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùñ **Tham s·ªë quan tr·ªçng**\n",
    "\n",
    "| Tham s·ªë | √ù nghƒ©a |\n",
    "|---------|--------|\n",
    "| `C`     | ƒêi·ªÅu ch·ªânh margin: C nh·ªè ‚Üí bi√™n r·ªông, C l·ªõn ‚Üí ph√¢n lo·∫°i ch·∫∑t |\n",
    "| `gamma` | M·ª©c ·∫£nh h∆∞·ªüng c·ªßa t·ª´ng ƒëi·ªÉm v·ªõi kernel RBF (gamma l·ªõn ‚Üí m√¥ h√¨nh ph·ª©c t·∫°p) |\n",
    "| `kernel`| Lo·∫°i kernel d√πng ƒë·ªÉ √°nh x·∫° d·ªØ li·ªáu |\n",
    "| `degree`| B·∫≠c c·ªßa ƒëa th·ª©c n·∫øu d√πng kernel `poly` |\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùñ **G·ª£i √Ω l·ª±a ch·ªçn tham s·ªë**\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'svc__C': [0.1, 1, 10, 100],\n",
    "    'svc__gamma': [0.001, 0.01, 0.1, 1]\n",
    "}\n",
    "grid = GridSearchCV(pipeline, params, cv=5)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **5.7.3. Minh h·ªça ho·∫°t ƒë·ªông c·ªßa SVM tuy·∫øn t√≠nh**\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "X, y = make_blobs(n_samples=100, centers=2, cluster_std=0.8, random_state=0)\n",
    "model = SVC(kernel='linear', C=1.0)\n",
    "model.fit(X, y)\n",
    "\n",
    "# H√†m v·∫Ω bi√™n ph√¢n t√°ch\n",
    "def plot_svm(model, X, y):\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap='autumn')\n",
    "    ax = plt.gca()\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "    yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "    YY, XX = np.meshgrid(yy, xx)\n",
    "    xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "    Z = model.decision_function(xy).reshape(XX.shape)\n",
    "    ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1],\n",
    "               linestyles=['--', '-', '--'])\n",
    "    plt.scatter(model.support_vectors_[:, 0], model.support_vectors_[:, 1],\n",
    "                s=100, linewidth=1, facecolors='none', edgecolors='k')\n",
    "    plt.show()\n",
    "\n",
    "plot_svm(model, X, y)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ **5.7.4. B√†i t·∫≠p th·ª±c h√†nh t·ª´ d·ªØ li·ªáu m·ªü**\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ **B√†i 1: Nh·∫≠n di·ªán khu√¥n m·∫∑t ng∆∞·ªùi n·ªïi ti·∫øng**\n",
    "\n",
    "**Ngu·ªìn d·ªØ li·ªáu**: [scikit-learn LFW dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_people.html)\n",
    "\n",
    "#### Y√™u c·∫ßu:\n",
    "- Nh·∫≠n di·ªán ng∆∞·ªùi trong ·∫£nh khu√¥n m·∫∑t (‚â•60 ·∫£nh/m·ªói ng∆∞·ªùi)\n",
    "\n",
    "#### C√°c b∆∞·ªõc:\n",
    "1. D√πng `fetch_lfw_people()`\n",
    "2. PCA ƒë·ªÉ gi·∫£m chi·ªÅu ·∫£nh\n",
    "3. `SVC(kernel='rbf')` k·∫øt h·ª£p `GridSearchCV`\n",
    "4. ƒê√°nh gi√° b·∫±ng `classification_report`\n",
    "\n",
    "#### L·ªùi gi·∫£i:\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "faces = fetch_lfw_people(min_faces_per_person=60)\n",
    "X_train, X_test, y_train, y_test = train_test_split(faces.data, faces.target, random_state=42)\n",
    "\n",
    "model = make_pipeline(PCA(n_components=150, whiten=True), SVC(kernel='rbf'))\n",
    "params = {'svc__C': [1, 10, 100], 'svc__gamma': [0.001, 0.005, 0.01]}\n",
    "grid = GridSearchCV(model, params)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=faces.target_names))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ **B√†i 2: Ph√¢n lo·∫°i b·ªánh ti·ªÉu ƒë∆∞·ªùng**\n",
    "\n",
    "**Ngu·ªìn d·ªØ li·ªáu**: [Kaggle ‚Äì Pima Indians Diabetes Dataset](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database)\n",
    "\n",
    "#### Y√™u c·∫ßu:\n",
    "- D·ª± ƒëo√°n b·ªánh ti·ªÉu ƒë∆∞·ªùng t·ª´ ch·ªâ s·ªë y t·∫ø (glucose, BMI, huy·∫øt √°p,...)\n",
    "\n",
    "#### C√°c b∆∞·ªõc:\n",
    "1. T·∫£i file `.csv` t·ª´ Kaggle\n",
    "2. Chu·∫©n h√≥a d·ªØ li·ªáu v·ªõi `StandardScaler`\n",
    "3. D√πng `SVC(kernel='rbf')` k·∫øt h·ª£p `GridSearchCV`\n",
    "4. ƒê√°nh gi√° b·∫±ng `classification_report`, `confusion_matrix`\n",
    "\n",
    "#### L·ªùi gi·∫£i:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "X = df.drop(\"Outcome\", axis=1)\n",
    "y = df[\"Outcome\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "pipeline = make_pipeline(StandardScaler(), SVC())\n",
    "params = {'svc__C': [0.1, 1, 10], 'svc__gamma': [0.01, 0.1, 1]}\n",
    "grid = GridSearchCV(pipeline, params)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix - Diabetes\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **T·ªïng k·∫øt**\n",
    "\n",
    "- SVM l√† thu·∫≠t to√°n ph√¢n lo·∫°i r·∫•t m·∫°nh d·ª±a tr√™n nguy√™n l√Ω **t·ªëi ƒëa h√≥a margin**.\n",
    "- C√≥ th·ªÉ x·ª≠ l√Ω c·∫£ d·ªØ li·ªáu **tuy·∫øn t√≠nh** v√† **phi tuy·∫øn** nh·ªù k·ªπ thu·∫≠t **kernel trick**.\n",
    "- C√°c tham s·ªë quan tr·ªçng (`C`, `gamma`, `kernel`) c√≥ th·ªÉ tinh ch·ªânh b·∫±ng `GridSearchCV`.\n",
    "- Ph√π h·ª£p v·ªõi b√†i to√°n y√™u c·∫ßu **ƒë·ªô ch√≠nh x√°c cao**, d·ªØ li·ªáu nhi·ªÖu √≠t v√† s·ªë l∆∞·ª£ng m·∫´u v·ª´a ph·∫£i.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
