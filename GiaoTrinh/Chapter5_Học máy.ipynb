{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0270a326",
   "metadata": {},
   "source": [
    "\n",
    "## **5.1. Machine Learning là gì?**\n",
    "\n",
    "### **5.1.1. Khái niệm cơ bản**\n",
    "\n",
    "Machine Learning (ML) là phương pháp xây dựng mô hình toán học từ dữ liệu. Mô hình có khả năng tự điều chỉnh để thích nghi với dữ liệu đã quan sát, từ đó dự đoán hoặc phân tích dữ liệu mới. Không giống như các chương trình truyền thống, ML học từ dữ liệu thay vì được lập trình rõ ràng từng bước.\n",
    "\n",
    "> 🌍 **Ứng dụng thực tế**:\n",
    "> - Dự đoán nhu cầu thị trường từ dữ liệu bán hàng  \n",
    "> - Nhận diện khuôn mặt, giọng nói  \n",
    "> - Phân loại thư rác, gợi ý video, sản phẩm  \n",
    "\n",
    "---\n",
    "\n",
    "### **5.1.2. Các loại học máy**\n",
    "\n",
    "- **Supervised Learning**: học từ dữ liệu có nhãn (ví dụ: dự đoán giá nhà, phân loại ảnh).\n",
    "- **Unsupervised Learning**: học từ dữ liệu không nhãn (ví dụ: phân cụm khách hàng).\n",
    "- **Semi-supervised Learning**: kết hợp cả hai khi nhãn bị thiếu hoặc không đầy đủ.\n",
    "\n",
    "> ✔️ **Lợi ích**: ML mở ra khả năng tự động hóa, mở rộng phân tích dữ liệu với tốc độ vượt trội so với khả năng con người.\n",
    "\n",
    "---\n",
    "\n",
    "## **5.2. Giới thiệu Scikit-Learn**\n",
    "\n",
    "### **5.2.1. Tổng quan về thư viện Scikit-Learn**\n",
    "\n",
    "Scikit-Learn là một thư viện mã nguồn mở nổi bật trong Python dùng để triển khai thuật toán ML, cung cấp:\n",
    "- Các mô hình học máy chuẩn hóa: classification, regression, clustering,...\n",
    "- Giao diện API thống nhất, dễ học, dễ dùng\n",
    "- Tích hợp với NumPy, Pandas, Matplotlib\n",
    "\n",
    "---\n",
    "\n",
    "### **5.2.2. Cách sử dụng Scikit-Learn theo 5 bước**\n",
    "\n",
    "1. **Chọn lớp mô hình**: `LinearRegression`, `KNeighborsClassifier`, v.v.  \n",
    "2. **Cài đặt siêu tham số**: như `n_neighbors=3`  \n",
    "3. **Chuẩn bị dữ liệu**: tách `X` và `y`  \n",
    "4. **Huấn luyện**: `.fit(X_train, y_train)`  \n",
    "5. **Dự đoán**: `.predict(X_test)` hoặc `.transform()`\n",
    "\n",
    "> 📌 **Ứng dụng thực tế**: nhanh chóng thử nghiệm nhiều mô hình để chọn mô hình tối ưu mà không viết lại nhiều code.\n",
    "\n",
    "---\n",
    "\n",
    "## **5.3. Siêu tham số và đánh giá mô hình**\n",
    "\n",
    "### **5.3.1. Siêu tham số là gì?**\n",
    "\n",
    "- Là các tham số được thiết lập trước khi huấn luyện, không học được từ dữ liệu.\n",
    "- Ví dụ: số lá trong cây quyết định, số cụm trong KMeans,...\n",
    "\n",
    "### **5.3.2. Xác thực mô hình – Tại sao cần?**\n",
    "\n",
    "Nếu đánh giá mô hình trên chính dữ liệu huấn luyện, ta dễ bị “ảo tưởng” về độ chính xác (overfitting). Giải pháp:\n",
    "- **Train/Test split**\n",
    "- **Cross-validation**: chia tập dữ liệu nhiều lần và hoán đổi vai trò train/test\n",
    "- **GridSearchCV**: thử nhiều bộ siêu tham số để tìm cái tốt nhất\n",
    "\n",
    "---\n",
    "\n",
    "### **5.3.3. Đánh đổi bias–variance**\n",
    "\n",
    "- **Bias cao** → mô hình đơn giản, underfitting  \n",
    "- **Variance cao** → mô hình quá phức tạp, overfitting  \n",
    "\n",
    "> ⚙️ **Thực hành tốt**: Dùng biểu đồ learning curve để theo dõi chất lượng huấn luyện và dự đoán theo kích thước dữ liệu.\n",
    "\n",
    "> 🌟 **Ứng dụng**: Tối ưu mô hình trong dự đoán tài chính, y tế, dự báo kinh doanh – nơi hiệu quả dự đoán quyết định lợi nhuận hoặc sinh mạng.\n",
    "\n",
    "---\n",
    "\n",
    "## **5.4. Kỹ thuật xây dựng đặc trưng (Feature Engineering)**\n",
    "\n",
    "### **5.4.1. Tại sao cần kỹ thuật đặc trưng?**\n",
    "\n",
    "Dữ liệu thực tế hiếm khi sẵn sàng đưa vào mô hình ML. Phải chuyển đổi về dạng số học được `[n_samples, n_features]` → quá trình đó gọi là feature engineering.\n",
    "\n",
    "---\n",
    "\n",
    "### **5.4.2. Một số kỹ thuật phổ biến**\n",
    "\n",
    "- **Biến phân loại** → One-hot encoding  \n",
    "- **Dữ liệu văn bản** → CountVectorizer, TF-IDF  \n",
    "- **Dữ liệu ảnh** → Vector đặc trưng  \n",
    "- **Dữ liệu thiếu** → Impute bằng trung bình, trung vị  \n",
    "- **Dẫn xuất đặc trưng** → thêm `x²`, `log(x)`, v.v.  \n",
    "- **Tự động hóa** → dùng `Pipeline` để gộp bước xử lý\n",
    "\n",
    "```python\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy=\"mean\"),\n",
    "    PolynomialFeatures(degree=3),\n",
    "    LinearRegression()\n",
    ")\n",
    "```\n",
    "\n",
    "> 🧠 **Ứng dụng**:  \n",
    "> - Biến văn bản feedback khách hàng thành dữ liệu định lượng  \n",
    "> - Tự động hóa xử lý dữ liệu trong hệ thống AI  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425d0121",
   "metadata": {},
   "source": [
    "\n",
    "## **5.5. Phân loại với Naive Bayes**\n",
    "\n",
    "### **5.5.1. Ý tưởng và công thức Bayes**\n",
    "\n",
    "Naive Bayes là nhóm thuật toán phân loại cực kỳ đơn giản, nhanh và hiệu quả trong nhiều tình huống. Thuật toán này dựa trên định lý Bayes để tính toán xác suất một nhãn (label) xuất hiện dựa trên các đặc trưng quan sát được:\n",
    "\n",
    "\\[\n",
    "P(L|X) = \\frac{P(X|L) \\cdot P(L)}{P(X)}\n",
    "\\]\n",
    "\n",
    "Trong đó:\n",
    "- \\( P(L|X) \\): xác suất có nhãn L khi biết X\n",
    "- \\( P(X|L) \\): xác suất tạo ra X từ lớp L (mô hình sinh)\n",
    "- \\( P(L) \\): xác suất tiên nghiệm của lớp\n",
    "- \\( P(X) \\): xác suất quan sát X (hằng số trong mọi lớp)\n",
    "\n",
    "> Điểm \"naive\" nằm ở giả định **các đặc trưng là độc lập** với nhau trong mỗi lớp – điều này không đúng trong thực tế nhưng giúp mô hình rất nhanh và vẫn khá hiệu quả.\n",
    "\n",
    "---\n",
    "\n",
    "### **5.5.2. Các biến thể Naive Bayes trong Scikit-Learn**\n",
    "\n",
    "| Biến thể | Mô tả | Dùng khi... |\n",
    "|----------|-------|-------------|\n",
    "| `GaussianNB` | Đặc trưng liên tục, phân phối chuẩn | Dữ liệu dạng số (điểm số, giá trị cảm biến) |\n",
    "| `MultinomialNB` | Đặc trưng rời rạc, là đếm số lượng | Phân loại văn bản, tần suất từ |\n",
    "| `BernoulliNB` | Đặc trưng nhị phân (0/1) | Dữ liệu kiểu có/không: có email, có đường dẫn |\n",
    "\n",
    "---\n",
    "\n",
    "### **5.5.3. Ví dụ: Gaussian Naive Bayes với dữ liệu 2 chiều**\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Tạo dữ liệu 2 cụm\n",
    "X, y = make_blobs(n_samples=100, centers=2, random_state=2, cluster_std=1.5)\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "model = GaussianNB()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Dự đoán dữ liệu mới\n",
    "rng = np.random.RandomState(0)\n",
    "Xnew = [-6, -14] + [14, 18] * rng.rand(2000, 2)\n",
    "ynew = model.predict(Xnew)\n",
    "\n",
    "# Vẽ kết quả\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='RdBu')\n",
    "plt.scatter(Xnew[:, 0], Xnew[:, 1], c=ynew, s=20, cmap='RdBu', alpha=0.1)\n",
    "plt.title(\"Biên quyết định của GaussianNB\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **5.5.4. Ví dụ: Phân loại văn bản với MultinomialNB**\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Lấy dữ liệu\n",
    "categories = ['sci.space', 'soc.religion.christian', 'comp.graphics']\n",
    "train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "\n",
    "# Pipeline\n",
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "model.fit(train.data, train.target)\n",
    "\n",
    "# Dự đoán\n",
    "labels = model.predict(test.data)\n",
    "```\n",
    "\n",
    "> Ứng dụng thực tế:\n",
    "> - Phân loại email: spam / không spam\n",
    "> - Gợi ý bài báo / phim / tin tức theo chủ đề\n",
    "> - Nhận dạng ngữ nghĩa của đoạn văn bản\n",
    "\n",
    "---\n",
    "\n",
    "### **5.5.5. Ưu điểm & nhược điểm**\n",
    "\n",
    "| Ưu điểm | Nhược điểm |\n",
    "|--------|------------|\n",
    "| Huấn luyện cực nhanh | Giả định độc lập không thực tế |\n",
    "| Có xác suất dự đoán (predict_proba) | Không tốt khi dữ liệu có mối quan hệ phức tạp |\n",
    "| Ít tham số cần điều chỉnh | Không học được tương quan giữa đặc trưng |\n",
    "\n",
    "---\n",
    "\n",
    "### **5.5.6. Các lỗi thường gặp**\n",
    "\n",
    "| Lỗi | Nguyên nhân | Cách xử lý |\n",
    "|-----|-------------|------------|\n",
    "| `ValueError: Input contains NaN` | Dữ liệu thiếu | Dùng `SimpleImputer` để thay thế |\n",
    "| Dự đoán sai toàn bộ | Không khớp định dạng đặc trưng | Kiểm tra `vectorizer`, xử lý trước dữ liệu |\n",
    "\n",
    "---\n",
    "\n",
    "## **5.5.7. Bài tập thực hành có lời giải**\n",
    "\n",
    "---\n",
    "\n",
    "### **Bài 1: Phân loại loài hoa Iris với GaussianNB**\n",
    "\n",
    "**Yêu cầu**: Dự đoán loài hoa dựa trên 4 đặc trưng.  \n",
    "**Dữ liệu**: `sklearn.datasets.load_iris()`\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(iris.data, iris.target, random_state=0)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(Xtrain, ytrain)\n",
    "y_pred = model.predict(Xtest)\n",
    "\n",
    "print(\"Độ chính xác:\", accuracy_score(ytest, y_pred))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Bài 2: Phân loại email là spam bằng MultinomialNB**\n",
    "\n",
    "**Yêu cầu**: Dự đoán xem email là spam hay không  \n",
    "**Dữ liệu**: file CSV gồm nội dung email + nhãn\n",
    "\n",
    "**Cách làm**:\n",
    "- Đọc file bằng Pandas\n",
    "- Tách tập huấn luyện và kiểm tra\n",
    "- Dùng `TfidfVectorizer()` + `MultinomialNB()`\n",
    "\n",
    "---\n",
    "\n",
    "### **Bài 3: Xây dựng hàm dự đoán văn bản theo chủ đề**\n",
    "\n",
    "```python\n",
    "def predict_category(s, train=train, model=model):\n",
    "    pred = model.predict([s])\n",
    "    return train.target_names[pred[0]]\n",
    "\n",
    "print(predict_category(\"NASA launched a new satellite\"))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Bài 4: So sánh GaussianNB và MultinomialNB trên tập Digits**\n",
    "\n",
    "**Yêu cầu**: Phân loại chữ số viết tay bằng 2 mô hình\n",
    "\n",
    "**Gợi ý**:\n",
    "- Dùng `load_digits()` từ `sklearn.datasets`\n",
    "- Chuẩn hóa dữ liệu: `StandardScaler()` hoặc `MinMaxScaler()`\n",
    "- Đánh giá bằng `accuracy_score`\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c0bc7c",
   "metadata": {},
   "source": [
    "\n",
    "## 🧠 **5.6. Phân hồi tuyến tính (Linear Regression)**\n",
    "\n",
    "### **5.6.1. Giới thiệu và nhu cầu**\n",
    "\n",
    "Phân hồi tuyến tính là một kỹ thuật cơ bản và mạnh mẽ trong học máy dùng để mô hình hóa mối quan hệ giữa một biến đầu ra liên tục và một hoặc nhiều biến đầu vào. Mô hình có dạng:\n",
    "\n",
    "\\[\n",
    "y = a_0 + a_1x_1 + a_2x_2 + \\dots + a_nx_n\n",
    "\\]\n",
    "\n",
    "> 🚀 **Nhu cầu và ứng dụng thực tế**:\n",
    "> - Dự đoán giá nhà, giá cổ phiếu, nhu cầu tiêu dùng\n",
    "> - Dự báo chỉ số kinh tế, chi phí vận hành\n",
    "> - Phân tích tác động của các yếu tố đến doanh số/bệnh tật\n",
    "\n",
    "### **5.6.2. Khi nào nên dùng Linear Regression**\n",
    "\n",
    "✅ **Nên dùng khi**:\n",
    "- Biến mục tiêu là **liên tục**  \n",
    "- Có lý do để tin rằng **quan hệ giữa các biến là tuyến tính**  \n",
    "- Cần mô hình đơn giản, dễ giải thích và triển khai\n",
    "\n",
    "🚫 **Không nên dùng khi**:\n",
    "- Dữ liệu có mối quan hệ phi tuyến phức tạp  \n",
    "- Có nhiều ngoại lệ (outliers)  \n",
    "- Số đặc trưng lớn hơn số mẫu (dễ gây overfitting)\n",
    "\n",
    "---\n",
    "\n",
    "### **5.6.3. Ưu điểm và nhược điểm**\n",
    "\n",
    "| ✅ Ưu điểm                          | ⚠️ Nhược điểm                             |\n",
    "|-----------------------------------|------------------------------------------|\n",
    "| Đơn giản, dễ giải thích           | Không phù hợp với quan hệ phi tuyến      |\n",
    "| Hiệu suất huấn luyện nhanh        | Nhạy cảm với ngoại lệ                    |\n",
    "| Cung cấp hệ số → hiểu được ảnh hưởng | Không hoạt động tốt với dữ liệu rối rắm, tương quan cao |\n",
    "\n",
    "---\n",
    "\n",
    "### **5.6.4. Cài đặt đơn giản với Scikit-Learn**\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Tạo dữ liệu mô phỏng\n",
    "x = np.random.rand(50) * 10\n",
    "y = 3 * x + 7 + np.random.randn(50)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x.reshape(-1, 1), y)\n",
    "\n",
    "print(\"Hệ số góc:\", model.coef_[0])\n",
    "print(\"Hệ số chặn:\", model.intercept_)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **5.6.5. Mở rộng mô hình**\n",
    "\n",
    "- **Hồi quy nhiều biến (Multivariate):** dự đoán dựa trên nhiều đặc trưng  \n",
    "- **Hồi quy phi tuyến:** kết hợp với `PolynomialFeatures`, hoặc các hàm cơ sở  \n",
    "- **Chính quy hóa (Regularization):** tránh overfitting  \n",
    "  - Ridge Regression (L2)\n",
    "  - Lasso Regression (L1)\n",
    "\n",
    "---\n",
    "\n",
    "## 🧪 **5.6.6. Bài tập thực hành với dữ liệu mở**\n",
    "\n",
    "---\n",
    "\n",
    "### 🎯 **Bài 1: Dự đoán giá nhà tại California**\n",
    "\n",
    "**Nguồn dữ liệu**: [Kaggle - California Housing Prices](https://www.kaggle.com/datasets/camnugent/california-housing-prices)\n",
    "\n",
    "#### **Yêu cầu**:\n",
    "Dự đoán giá trung vị của nhà tại California từ các đặc trưng như: diện tích, mật độ dân cư, số phòng,…\n",
    "\n",
    "#### **Các bước giải**:\n",
    "\n",
    "1. Tải và đọc dữ liệu  \n",
    "2. Tiền xử lý: bỏ giá trị thiếu  \n",
    "3. Chia dữ liệu train/test  \n",
    "4. Huấn luyện với `LinearRegression()`  \n",
    "5. Đánh giá mô hình bằng R², RMSE  \n",
    "6. Phân tích ý nghĩa hệ số\n",
    "\n",
    "#### **Lời giải minh họa**:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Bước 1-2: Tải và xử lý\n",
    "data = pd.read_csv(\"housing.csv\")\n",
    "data = data.dropna()\n",
    "X = data.drop(\"median_house_value\", axis=1)\n",
    "y = data[\"median_house_value\"]\n",
    "\n",
    "# Bước 3: Tách tập dữ liệu\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Bước 4: Huấn luyện mô hình\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Bước 5: Đánh giá\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"R²:\", r2_score(y_test, y_pred))\n",
    "print(\"RMSE:\", mean_squared_error(y_test, y_pred, squared=False))\n",
    "\n",
    "# Bước 6: Phân tích hệ số\n",
    "print(pd.Series(model.coef_, index=X.columns))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🎯 **Bài 2: Dự đoán chất lượng rượu vang đỏ**\n",
    "\n",
    "**Nguồn dữ liệu**: [Kaggle - Red Wine Quality Dataset](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009)\n",
    "\n",
    "#### **Yêu cầu**:\n",
    "Dự đoán điểm chất lượng của rượu vang đỏ từ các chỉ số hóa học (pH, độ chua, cồn,...)\n",
    "\n",
    "#### **Các bước giải**:\n",
    "\n",
    "1. Tải dữ liệu `.csv` và đọc bằng Pandas  \n",
    "2. Chia tập train/test  \n",
    "3. Huấn luyện với `LinearRegression()`  \n",
    "4. Đánh giá bằng R² và RMSE  \n",
    "5. Diễn giải tác động của từng thông số hóa học\n",
    "\n",
    "#### **Lời giải minh họa**:\n",
    "\n",
    "```python\n",
    "data = pd.read_csv(\"winequality-red.csv\", sep=';')\n",
    "X = data.drop(\"quality\", axis=1)\n",
    "y = data[\"quality\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"R²:\", r2_score(y_test, y_pred))\n",
    "print(\"RMSE:\", mean_squared_error(y_test, y_pred, squared=False))\n",
    "print(\"Hệ số:\", pd.Series(model.coef_, index=X.columns))\n",
    "```\n",
    "\n",
    "> 🧠 **Phân tích**: Những đặc trưng có hệ số dương lớn → đóng góp tích cực cho chất lượng rượu.\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 Tổng kết\n",
    "\n",
    "- Hồi quy tuyến tính là mô hình nền tảng, dễ tiếp cận và có khả năng diễn giải rõ ràng.\n",
    "- Dù đơn giản, nhưng vẫn hiệu quả nếu dữ liệu phù hợp (tuyến tính, không nhiều ngoại lệ).\n",
    "- Hai bài tập với dữ liệu thực tế giúp sinh viên vận dụng toàn bộ kiến thức để mô hình hóa, giải thích và đánh giá hiệu quả.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb8b180",
   "metadata": {},
   "source": [
    "\n",
    "# **5.7. Support Vector Machines (SVM)**\n",
    "\n",
    "---\n",
    "\n",
    "## **5.7.1. Giới thiệu và ứng dụng**\n",
    "\n",
    "SVM (Support Vector Machines) là một thuật toán học có giám sát rất mạnh cho **phân loại nhị phân** và **hồi quy**. Mục tiêu của SVM là tìm một **siêu phẳng (hyperplane)** để phân tách hai lớp dữ liệu sao cho **khoảng cách (margin)** đến các điểm gần nhất của mỗi lớp là **lớn nhất**.\n",
    "\n",
    "> 🎯 **Ứng dụng thực tế:**\n",
    "> - Nhận diện khuôn mặt  \n",
    "> - Phân loại thư rác  \n",
    "> - Phân tích tín dụng, y tế, gen học  \n",
    "> - Dự đoán lỗi kỹ thuật hoặc hành vi bất thường  \n",
    "\n",
    "---\n",
    "\n",
    "## **5.7.2. Lý thuyết & công thức toán học**\n",
    "\n",
    "### ❖ **Mục tiêu của SVM tuyến tính**\n",
    "\n",
    "Với tập dữ liệu nhị phân \\( y_i \\in \\{-1, +1\\} \\), bài toán SVM tìm \\( \\mathbf{w}, b \\) sao cho:\n",
    "\n",
    "\\[\n",
    "\\min_{\\mathbf{w}, b} \\ \\frac{1}{2} \\|\\mathbf{w}\\|^2\n",
    "\\quad \\text{với điều kiện:} \\quad y_i (\\mathbf{w} \\cdot \\mathbf{x}_i + b) \\geq 1\n",
    "\\]\n",
    "\n",
    "- \\( \\mathbf{x}_i \\): điểm dữ liệu đầu vào  \n",
    "- \\( y_i \\): nhãn của mẫu thứ \\( i \\)  \n",
    "- \\( \\mathbf{w} \\): vector pháp tuyến của siêu phẳng  \n",
    "- \\( b \\): độ lệch (bias)  \n",
    "- \\( \\|\\mathbf{w}\\| \\): độ dài vector → liên quan đến độ rộng của margin\n",
    "\n",
    "### ❖ **Soft Margin – cho phép lỗi**\n",
    "\n",
    "Trong thực tế, dữ liệu có thể không phân tách hoàn toàn → dùng biến slack \\( \\xi_i \\) và tham số \\( C \\):\n",
    "\n",
    "\\[\n",
    "\\min_{\\mathbf{w}, b, \\xi} \\ \\frac{1}{2} \\|\\mathbf{w}\\|^2 + C \\sum_{i=1}^n \\xi_i\n",
    "\\quad \\text{với} \\quad y_i (\\mathbf{w} \\cdot \\mathbf{x}_i + b) \\geq 1 - \\xi_i\n",
    "\\]\n",
    "\n",
    "- \\( C \\): điều khiển mức độ **chấp nhận lỗi**\n",
    "  - \\( C \\) lớn → ít cho phép lỗi (overfitting)\n",
    "  - \\( C \\) nhỏ → cho phép lỗi nhiều hơn (tổng quát tốt hơn)\n",
    "\n",
    "---\n",
    "\n",
    "### ❖ **Kernel Trick – phân lớp phi tuyến**\n",
    "\n",
    "Khi dữ liệu không tuyến tính, ta ánh xạ vào không gian cao chiều thông qua hàm kernel:\n",
    "\n",
    "\\[\n",
    "K(\\mathbf{x}, \\mathbf{x'}) = \\phi(\\mathbf{x}) \\cdot \\phi(\\mathbf{x'})\n",
    "\\]\n",
    "\n",
    "| Kernel        | Công thức                                           | Khi nên dùng                      |\n",
    "|---------------|-----------------------------------------------------|-----------------------------------|\n",
    "| `linear`      | \\( \\mathbf{x} \\cdot \\mathbf{x'} \\)                  | Dữ liệu phân tách tuyến tính      |\n",
    "| `poly`        | \\( (\\mathbf{x} \\cdot \\mathbf{x'} + 1)^d \\)          | Quan hệ dạng đa thức              |\n",
    "| `rbf`         | \\( \\exp(-\\gamma \\|\\mathbf{x} - \\mathbf{x'}\\|^2) \\)  | Phi tuyến, phổ biến nhất          |\n",
    "| `sigmoid`     | \\( \\tanh(\\alpha \\mathbf{x} \\cdot \\mathbf{x'} + c) \\)| Ít dùng, tương tự mạng thần kinh  |\n",
    "\n",
    "---\n",
    "\n",
    "### ❖ **Tham số quan trọng**\n",
    "\n",
    "| Tham số | Ý nghĩa |\n",
    "|---------|--------|\n",
    "| `C`     | Điều chỉnh margin: C nhỏ → biên rộng, C lớn → phân loại chặt |\n",
    "| `gamma` | Mức ảnh hưởng của từng điểm với kernel RBF (gamma lớn → mô hình phức tạp) |\n",
    "| `kernel`| Loại kernel dùng để ánh xạ dữ liệu |\n",
    "| `degree`| Bậc của đa thức nếu dùng kernel `poly` |\n",
    "\n",
    "---\n",
    "\n",
    "### ❖ **Gợi ý lựa chọn tham số**\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'svc__C': [0.1, 1, 10, 100],\n",
    "    'svc__gamma': [0.001, 0.01, 0.1, 1]\n",
    "}\n",
    "grid = GridSearchCV(pipeline, params, cv=5)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **5.7.3. Minh họa hoạt động của SVM tuyến tính**\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "X, y = make_blobs(n_samples=100, centers=2, cluster_std=0.8, random_state=0)\n",
    "model = SVC(kernel='linear', C=1.0)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Hàm vẽ biên phân tách\n",
    "def plot_svm(model, X, y):\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap='autumn')\n",
    "    ax = plt.gca()\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "    yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "    YY, XX = np.meshgrid(yy, xx)\n",
    "    xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "    Z = model.decision_function(xy).reshape(XX.shape)\n",
    "    ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1],\n",
    "               linestyles=['--', '-', '--'])\n",
    "    plt.scatter(model.support_vectors_[:, 0], model.support_vectors_[:, 1],\n",
    "                s=100, linewidth=1, facecolors='none', edgecolors='k')\n",
    "    plt.show()\n",
    "\n",
    "plot_svm(model, X, y)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🧪 **5.7.4. Bài tập thực hành từ dữ liệu mở**\n",
    "\n",
    "---\n",
    "\n",
    "### 🎯 **Bài 1: Nhận diện khuôn mặt người nổi tiếng**\n",
    "\n",
    "**Nguồn dữ liệu**: [scikit-learn LFW dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_people.html)\n",
    "\n",
    "#### Yêu cầu:\n",
    "- Nhận diện người trong ảnh khuôn mặt (≥60 ảnh/mỗi người)\n",
    "\n",
    "#### Các bước:\n",
    "1. Dùng `fetch_lfw_people()`\n",
    "2. PCA để giảm chiều ảnh\n",
    "3. `SVC(kernel='rbf')` kết hợp `GridSearchCV`\n",
    "4. Đánh giá bằng `classification_report`\n",
    "\n",
    "#### Lời giải:\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "faces = fetch_lfw_people(min_faces_per_person=60)\n",
    "X_train, X_test, y_train, y_test = train_test_split(faces.data, faces.target, random_state=42)\n",
    "\n",
    "model = make_pipeline(PCA(n_components=150, whiten=True), SVC(kernel='rbf'))\n",
    "params = {'svc__C': [1, 10, 100], 'svc__gamma': [0.001, 0.005, 0.01]}\n",
    "grid = GridSearchCV(model, params)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=faces.target_names))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🎯 **Bài 2: Phân loại bệnh tiểu đường**\n",
    "\n",
    "**Nguồn dữ liệu**: [Kaggle – Pima Indians Diabetes Dataset](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database)\n",
    "\n",
    "#### Yêu cầu:\n",
    "- Dự đoán bệnh tiểu đường từ chỉ số y tế (glucose, BMI, huyết áp,...)\n",
    "\n",
    "#### Các bước:\n",
    "1. Tải file `.csv` từ Kaggle\n",
    "2. Chuẩn hóa dữ liệu với `StandardScaler`\n",
    "3. Dùng `SVC(kernel='rbf')` kết hợp `GridSearchCV`\n",
    "4. Đánh giá bằng `classification_report`, `confusion_matrix`\n",
    "\n",
    "#### Lời giải:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "X = df.drop(\"Outcome\", axis=1)\n",
    "y = df[\"Outcome\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "pipeline = make_pipeline(StandardScaler(), SVC())\n",
    "params = {'svc__C': [0.1, 1, 10], 'svc__gamma': [0.01, 0.1, 1]}\n",
    "grid = GridSearchCV(pipeline, params)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix - Diabetes\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ **Tổng kết**\n",
    "\n",
    "- SVM là thuật toán phân loại rất mạnh dựa trên nguyên lý **tối đa hóa margin**.\n",
    "- Có thể xử lý cả dữ liệu **tuyến tính** và **phi tuyến** nhờ kỹ thuật **kernel trick**.\n",
    "- Các tham số quan trọng (`C`, `gamma`, `kernel`) có thể tinh chỉnh bằng `GridSearchCV`.\n",
    "- Phù hợp với bài toán yêu cầu **độ chính xác cao**, dữ liệu nhiễu ít và số lượng mẫu vừa phải.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
